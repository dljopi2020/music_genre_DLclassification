# music_genre_DLclassification
 In this repository music genre classification systems (i.e., CNN; RNN) are implemented to classify music genres based on audio fragments of songs in a WAV format. The fragments are based on whole songs found in the GTZAN dataset. Additionally, we augment our data-set by dividing the fragments in subsets in order to improve the training step in our models.
 
 Simply run the code. Firstly, the data will be loaded from our Google drive and subsequently prepared according to fragment sizes of 5, 10, 15 and 30 seconds. Secondly, the CNN and RNN (i.e. LSTM) will be set-up. Thirdly, the models will be trained. Fourthly, the models are implemented for the test data-set. Fiftly, results are plotted.
